{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbWHV3UFeUXv",
        "outputId": "a6321b28-b0c9-4275-c28f-2497c8967087"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "3/3 [==============================] - 6s 11ms/step - loss: 0.0000e+00 - accuracy: 0.1667\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - accuracy: 0.6667\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - accuracy: 0.8333\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 0s 103ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 488ms/step\n",
            "Recommended hashtags: ['travel', 'travel']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Sample data: You should replace this with your own dataset\n",
        "data = pd.DataFrame({'user_id': [1, 2, 3, 1, 2, 3],\n",
        "                     'message': ['I love #travel', 'Exploring new places', 'Foodie #food',\n",
        "                                 'Planning a #trip', 'Travel adventures', 'Delicious #food']})\n",
        "\n",
        "# Preprocess the data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(data['message'])\n",
        "sequences = tokenizer.texts_to_sequences(data['message'])\n",
        "\n",
        "X = pad_sequences(sequences)  # Padded sequences for RNN input\n",
        "\n",
        "# Create labels (hashtags)\n",
        "labels = data['message'].str.extractall(r'#(\\w+)')[0].tolist()\n",
        "\n",
        "# Build an RNN model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=32, input_length=X.shape[1]))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(len(labels), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model (you should train on a larger dataset)\n",
        "model.fit(X, np.zeros((len(X), len(labels))), epochs=10, batch_size=2)\n",
        "\n",
        "# Make hashtag recommendations for a user (user_id=1)\n",
        "user_messages = data[data['user_id'] == 2]['message']\n",
        "user_sequences = tokenizer.texts_to_sequences(user_messages)\n",
        "user_X = pad_sequences(user_sequences, maxlen=X.shape[1])\n",
        "\n",
        "recommendations = model.predict(user_X)\n",
        "recommended_hashtags = [labels[i] for i in recommendations.argmax(axis=1)]\n",
        "print(\"Recommended hashtags:\", recommended_hashtags)\n"
      ]
    }
  ]
}